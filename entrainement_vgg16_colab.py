# -*- coding: utf-8 -*-
"""ENTRAINEMENT_VGG16

Automatically generated by Colaboratory.
Architecture de VGG16


```
Input: 224x224x3 image

[Conv3x3x64] x 2
[MaxPool2x2 (stride 2)]

[Conv3x3x128] x 2
[MaxPool2x2 (stride 2)]

[Conv3x3x256] x 3
[MaxPool2x2 (stride 2)]

[Conv3x3x512] x 3
[MaxPool2x2 (stride 2)]

[Conv3x3x512] x 3
[MaxPool2x2 (stride 2)]

[Flatten]

[Dense 4096]
[Dense 4096]
[Dense 1000] (pour ImageNet)

[Softmax]

```
"""

import torch
import os
import keras
import cv2
import numpy as np

from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D
from keras import optimizers
from keras.models import Sequential
from keras.layers import Input, Lambda, Dense, Flatten, Dropout
from keras.models import Model

from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

from matplotlib import pyplot as plt

from sklearn.metrics import confusion_matrix
import seaborn as sns

from sklearn.model_selection import train_test_split
import xml.etree.ElementTree as ET

IMAGE_SIZE = 224
nombre_epoch = 50
nombre_batch = 32

def read_xml(fich_xml: str):
  tree = ET.parse(fich_xml) #Contient la structure du fichier XML
  root = tree.getroot() #Contient la root du fichier XML <annotation> dans mon fichier

  list_with_all_boxes = []

  for obj in root.iter('object'):

    filename = root.find('filename').text
    width = int(root.find('size/width').text)
    height = int(root.find('size/height').text)

    ymin = int(obj.find('bndbox/ymin').text)/(height/IMAGE_SIZE)
    ymax = int(obj.find('bndbox/ymax').text)/(height/IMAGE_SIZE)
    xmin = int(obj.find('bndbox/xmin').text)/(width/IMAGE_SIZE)
    xmax = int(obj.find('bndbox/xmax').text)/(width/IMAGE_SIZE)

    list_with_single_boxes = [xmin, ymin, xmax, ymax]
    list_with_all_boxes.append(list_with_single_boxes)

    return filename, list_with_all_boxes

model = keras.Sequential()
model.add(VGG16( weights="imagenet", include_top=False, input_shape=[IMAGE_SIZE,IMAGE_SIZE,3]))

model.add(Flatten())
model.add(Dropout(0.5))


model.add(Dense(128, activation="relu"))
model.add(Dense(128, activation="relu"))
model.add(Dense(64, activation="relu"))
model.add(Dense(4, activation="sigmoid"))

model.layers[-7].trainable = False

model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])

chemin_annot_xml = '/content/annotations'
chemin_images = '/content/images'

list_images = []
list_path =[]
list_bboxes = []

for fich in sorted(os.listdir(chemin_annot_xml)):
  xml_path = os.path.join(chemin_annot_xml, fich)
  filename, bboxes = read_xml(xml_path)

  image_path = os.path.join(chemin_images, filename)
  list_path.append(image_path)
  image_open = cv2.imread(image_path)
  image_resized = cv2.resize(image_open, (IMAGE_SIZE, IMAGE_SIZE))

  list_images.append(image_resized)

  list_bboxes.extend(bboxes)

X = np.array(list_images)
Y = np.array(list_bboxes)

print(len(list_bboxes))

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

X_norm = x_train /255
Y_norm = y_train / IMAGE_SIZE

print(Y_norm.shape)

model.summary()

model_train = model.fit(X_norm, Y_norm, epochs=nombre_epoch, batch_size=nombre_batch)

norm_xtest = x_test/255
norm_ytest = y_test/IMAGE_SIZE

predictions = model.predict(norm_xtest)

plt.plot(model_train.history['loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

plt.plot(model_train.history['accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

model.save_weights('modele_licenseplate_50epoch.h5')

loss, accuracy = model.evaluate(norm_xtest, norm_ytest)
print("Perte sur l'ensemble de test:", loss)
print("Précision sur l'ensemble de test:", accuracy)

print(predictions)

predicted_classes = np.argmax(predictions, axis=1)

true_classes = np.argmax(norm_ytest, axis=1)

confusion_mtx = confusion_matrix(true_classes, predicted_classes)

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Classe prédite')
plt.ylabel('Classe réelle')
plt.title('Matrice de confusion')
plt.show()

image_width = 224
image_height = 224

bbox_convertie = []

for i in predictions:

  xl_pred, yl_pred, xa_pred, ya_pred = i

  xl_pred_px = xl_pred * image_width
  yl_pred_px = yl_pred * image_height
  xa_pred_px = xa_pred * image_width
  ya_pred_px = ya_pred * image_height

  bbox_convertie.append([xl_pred_px, yl_pred_px, xa_pred_px, ya_pred_px])

test_image = x_test[1]
image_copy = test_image.copy()

import matplotlib.pyplot as plt
import cv2

num_cols = 8
num_rows = 10

plt.figure(figsize=(15, 15))

output_dir = "saved_images_2"
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

for i in range(20):

  test_image = x_test[i]
  image_copy = test_image.copy()

  xmin, ymin, xmax, ymax = bbox_convertie[i]

  pt1 = (int(xmin), int(ymin))
  pt2 = (int(xmax), int(ymax))
  color = (0, 255, 0)
  thickness = 2

  cv2.rectangle(image_copy, pt1, pt2, color, thickness)

  image_copy = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)

  file_path = os.path.join(output_dir, f"image_{i}.png")

  cv2.imwrite(file_path, image_copy)

print("Toutes les images ont été sauvegardées dans le dossier :", output_dir)
